ğŸ– AIÃ—ç„¼è‚‰ ãƒãƒƒã‚«ã‚½ãƒ³
ğŸš€ æ¦‚è¦
æœ¬ãƒãƒƒã‚«ã‚½ãƒ³ã§ã¯ã€ŒAIÃ—ç„¼è‚‰ã€ã‚’ãƒ†ãƒ¼ãƒã«ã€AIæŠ€è¡“ã‚’æ´»ç”¨ã—ãŸç„¼è‚‰ã®æ–°ã—ã„ä½“é¨“ã‚’å‰µå‡ºã—ã¾ã™ã€‚
2.5æ™‚é–“ã®çŸ­æ™‚é–“ã§ã€ç™ºæƒ³â†’ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°â†’ç™ºè¡¨ã‚’è¡Œã„ã€ç„¼è‚‰ã®æ¥½ã—ã¿æ–¹ã‚’æ‹¡å¼µã™ã‚‹ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å½¢ã«ã—ã¾ã™ã€‚

ğŸ—“ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆ2.5hï¼‰
å°å…¥ï¼ˆ10åˆ†ï¼‰

ãƒãƒƒã‚«ã‚½ãƒ³ã¨ã¯ï¼Ÿ
AIã®åŸºç¤ï¼†æ´»ç”¨ä¾‹ï¼ˆç„¼è‚‰ã«ãŠã‘ã‚‹èª²é¡Œã¨AIã®å¯èƒ½æ€§ï¼‰
é«˜é€Ÿãƒãƒƒã‚«ã‚½ãƒ³ï¼ˆ15åˆ†ï¼‰

ãƒŸãƒ‹ãƒ†ãƒ¼ãƒï¼šã€ŒAIÃ—ç¬‘ã„ã€
5åˆ†ã§ã‚¢ã‚¤ãƒ‡ã‚¢ç™ºæƒ³ â†’ 5åˆ†ã§æ•´ç† â†’ 1åˆ†ãƒ—ãƒ¬ã‚¼ãƒ³
ãƒ¡ã‚¤ãƒ³ãƒãƒƒã‚«ã‚½ãƒ³ï¼ˆ90åˆ†ï¼‰

ã‚¢ã‚¤ãƒ‡ã‚¢ç™ºæ•£ï¼ˆ20åˆ†ï¼‰ï¼šç„¼è‚‰ã®èª²é¡Œã‚’æ´—ã„å‡ºã—ã€AIã§è§£æ±ºç­–ã‚’è€ƒãˆã‚‹
ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆ60åˆ†ï¼‰ï¼šç°¡å˜ãªãƒ‡ãƒ¢ãƒ»UIã‚¹ã‚±ãƒƒãƒã‚’ä½œæˆ
ç™ºè¡¨æº–å‚™ï¼ˆ5åˆ†ï¼‰ï¼šç™ºè¡¨ã‚¹ãƒ©ã‚¤ãƒ‰ã‚„ãƒ‡ãƒ¢ã‚’æ•´ç†
ç™ºè¡¨ï¼†ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆ25åˆ†ï¼‰

å„ãƒãƒ¼ãƒ 3åˆ†ç™ºè¡¨ï¼‹è³ªç–‘å¿œç­”
å‚åŠ è€…å…¨å“¡ã§æŠ•ç¥¨ã—ã€æœ€ã‚‚è©¦ã—ã¦ã¿ãŸã„ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’é¸å‡º
ğŸ’¡ ãƒ†ãƒ¼ãƒï¼šã€ŒAIÃ—ç„¼è‚‰ã€
ğŸ”¥ ã“ã‚“ãªèª²é¡Œã‚’AIã§è§£æ±ºã§ãã‚‹ã‹ã‚‚ï¼Ÿ
ç„¼ãåŠ æ¸›ã®æœ€é©åŒ–ï¼šã€Œè‚‰ã®ç„¼ãã™ããƒ»ç”Ÿç„¼ã‘ã‚’é˜²ãAIã€
ä¼šè©±ã‚’ç››ã‚Šä¸Šã’ã‚‹ï¼šã€Œç„¼è‚‰ãƒˆãƒ¼ã‚¯ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã€
æ³¨æ–‡æœ€é©åŒ–ï¼šã€Œã‚ãªãŸã«ãƒ”ãƒƒã‚¿ãƒªã®ç„¼è‚‰ã‚»ãƒƒãƒˆã‚’ææ¡ˆã€
é£Ÿã¹æ”¾é¡Œæ”»ç•¥ï¼šã€Œæº€è¶³åº¦UPã®æœ€é©ãªé£Ÿã¹æ–¹ã‚’AIãŒè¨ˆç®—ã€
åº—èˆ—DXï¼šã€Œæ··é›‘äºˆæ¸¬ãƒ»æ›æ°—ç®¡ç†ãƒ»æ³¨æ–‡ã‚¢ã‚·ã‚¹ãƒˆã€
ğŸ›  ä½¿ç”¨ãƒ„ãƒ¼ãƒ«ãƒ»æŠ€è¡“
ã›ã£ã‹ããªã®ã§ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã—ã¾ã—ã‚‡ã†ï¼
ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã€ãƒ­ãƒ¼ã‚³ãƒ¼ãƒ‰ã‚‚ä¸€å¿œOKï¼
ChatGPT / ç”»åƒç”ŸæˆAI / Googleã‚¹ãƒ©ã‚¤ãƒ‰ / Miro / Figma ãªã©æ´»ç”¨ã—ã‚ˆã†
ğŸ¤ ç™ºè¡¨ã®ãƒã‚¤ãƒ³ãƒˆ
ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆä¾‹ï¼šã€ŒAIç„¼è‚‰ã‚³ãƒ³ã‚·ã‚§ãƒ«ã‚¸ãƒ¥ã€ï¼‰
è§£æ±ºã™ã‚‹èª²é¡Œ
AIã®æ´»ç”¨æ–¹æ³•
å®Ÿéš›ã®åˆ©ç”¨ã‚·ãƒ¼ãƒ³
ä»Šå¾Œã®ç™ºå±•å¯èƒ½æ€§
ğŸ¯ ã‚´ãƒ¼ãƒ«
ç„¼è‚‰Ã—AIã®æ–°ã—ã„ä½“é¨“ã‚’è€ƒãˆã‚‹
çŸ­æ™‚é–“ã§ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’ä½œã‚‹
ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’æ¥½ã—ã¿ãªãŒã‚‰ç™ºè¡¨ã™ã‚‹
ğŸ”¥ ã•ã‚ã€AIã®åŠ›ã§ç„¼è‚‰ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ã‚ˆã†ï¼ ğŸ–


{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# åŸºæœ¬\n",
        "a = \"ç§ã¯\"\n",
        "b = \"èŠç”°ã§ã™\"\n",
        "c = a + b\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rZPCcXaNKSW",
        "outputId": "24c344d8-f802-4f5f-94b1-8ddeb6528e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç§ã¯èŠç”°ã§ã™\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neko_list = [\"peko\", \"pochi\", \"kuro\", \"tama\"]\n",
        "print(\"ãƒªã‚¹ãƒˆå…¨éƒ¨è¡¨ç¤ºã—ã¦ã¿ã‚‹ï¼š\",neko_list)\n",
        "print(\"æœ€åˆã®è¦ç´ ã ã‘è¡¨ç¤ºã—ã¦ã¿ã‚‹ï¼š\",neko_list[0])\n",
        "print(\"æœ€åˆã‹ã‚‰3å€‹è¡¨ç¤ºã—ã¦ã¿ã‚‹ï¼š\",neko_list[0:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to34ND--NaQI",
        "outputId": "f7ee13db-f052-42c2-b34b-b5503c8ab787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ãƒªã‚¹ãƒˆå…¨éƒ¨è¡¨ç¤ºã—ã¦ã¿ã‚‹ï¼š ['peko', 'pochi', 'kuro', 'tama']\n",
            "æœ€åˆã®è¦ç´ ã ã‘è¡¨ç¤ºã—ã¦ã¿ã‚‹ï¼š peko\n",
            "æœ€åˆã‹ã‚‰3å€‹è¡¨ç¤ºã—ã¦ã¿ã‚‹ï¼š ['peko', 'pochi', 'kuro']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "T2Q5DbgeOqtl",
        "outputId": "4e97b127-5ca0-4de6-e41d-cba493f47135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI APIã‚­ãƒ¼ã‚’è¨­å®š\n",
        "OPENAI_API_KEY = \"\""
      ],
      "metadata": {
        "id": "IWt2JlduO7K5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Anr4ghzlbXqA",
        "outputId": "a35e2288-d603-4141-acb2-a15bd7ff4967",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPTã¨å¯¾è©±ã‚’é–‹å§‹ã—ã¾ã™ã€‚'exit'ã¨å…¥åŠ›ã™ã‚‹ã¨çµ‚äº†ã—ã¾ã™ã€‚\n",
            "\n",
            "You: ãŠã£ã™ï¼\n",
            "ChatGPT: ãŠã£ã™ï¼å…ƒæ°—ã‹ï¼Ÿä»Šæ—¥ã‚‚ä¸€ç·’ã«ä¿®è¡Œé ‘å¼µã‚ã†ãœï¼ä½•ã‹æ‰‹ä¼ãˆã‚‹ã“ã¨ãŒã‚ã£ãŸã‚‰ã€é æ…®ãªãè¨€ã£ã¦ãã‚Œã‚ˆãªï¼\n",
            "You: ã“ã‚“ã«ã¡ã¯\n",
            "ChatGPT: ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã¯ã©ã‚“ãªã“ã¨ã‚’ã™ã‚‹äºˆå®šã ï¼Ÿä½•ã‹ä¸€ç·’ã«è©±ã—ãŸã„ã“ã¨ã‚„èããŸã„ã“ã¨ãŒã‚ã£ãŸã‚‰æ•™ãˆã¦ãã‚Œã‚ˆï¼\n",
            "You: exit\n",
            "çµ‚äº†ã—ã¾ã™ã€‚\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå¿…è¦ãªã‚‰å¾Œã‹ã‚‰å¤‰æ›´å¯èƒ½ï¼‰\n",
        "SYSTEM_PROMPT = \"ã‚ãªãŸã¯å„ªç§€ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\"  # ã“ã“ã‚’å¤‰æ›´ã™ã‚Œã°ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰æ›´å¯èƒ½\n",
        "#SYSTEM_PROMPT = \"ã‚ãªãŸã¯å„ªç§€ãªãƒ‰ãƒ©ã‚´ãƒ³ãƒœãƒ¼ãƒ«å­«æ‚Ÿç©ºã§ã™ã€‚\"\n",
        "#SYSTEM_PROMPT = \"ã‚ãªãŸã¯ã‚¸ãƒ§ãƒ¼ã‚¯ãŒå¾—æ„ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚å¿…ãšé¢ç™½ã„è¿”ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚\"\n",
        "\n",
        "def chat_with_gpt():\n",
        "    print(\"ChatGPTã¨å¯¾è©±ã‚’é–‹å§‹ã—ã¾ã™ã€‚'exit'ã¨å…¥åŠ›ã™ã‚‹ã¨çµ‚äº†ã—ã¾ã™ã€‚\\n\")\n",
        "\n",
        "    # APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ\n",
        "    client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "    # åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å«ã‚€ï¼‰\n",
        "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"çµ‚äº†ã—ã¾ã™ã€‚\")\n",
        "            break\n",
        "\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        reply = response.choices[0].message.content\n",
        "        print(\"ChatGPT:\", reply)\n",
        "\n",
        "        # å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ \n",
        "        messages.append({\"role\": \"assistant\", \"content\": reply})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chat_with_gpt()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XFp94tuUbrdG",
        "outputId": "94ae7e58-78a7-4c1d-9f8a-39c92766d561"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.2 (from gradio)\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.20.0-py3-none-any.whl (62.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m119.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.11 ffmpy-0.5.0 gradio-5.20.0 gradio-client-1.7.2 groovy-0.1.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.9 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.0 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå¤‰æ›´å¯èƒ½ï¼‰\n",
        "SYSTEM_PROMPT = \"ã‚ãªãŸã¯å„ªç§€ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\"\n",
        "\n",
        "# APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ\n",
        "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "def chat_with_gpt(messages):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=messages\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def chat_interface(user_input, history):\n",
        "    if history is None:\n",
        "        history = []\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}] + [\n",
        "        {\"role\": \"user\", \"content\": msg[0]} if isinstance(msg, list) else msg for msg in history\n",
        "    ]\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    reply = chat_with_gpt(messages)\n",
        "    history.append([user_input, reply])\n",
        "\n",
        "    return history, \"\"\n",
        "\n",
        "with gr.Blocks() as iface:\n",
        "    gr.Markdown(\"# ChatGPT Web Interface\\nOpenAIã®GPTãƒ¢ãƒ‡ãƒ«ã¨ä¼šè©±ã§ãã¾ã™ã€‚\")\n",
        "    chatbot = gr.Chatbot()\n",
        "    user_input = gr.Textbox(label=\"ã‚ãªãŸã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\")\n",
        "    submit_btn = gr.Button(\"é€ä¿¡\")\n",
        "\n",
        "    history = gr.State([])\n",
        "\n",
        "    submit_btn.click(chat_interface, inputs=[user_input, history], outputs=[chatbot, user_input])\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "6qcoacAGbfH-",
        "outputId": "fdbdb626-ac74-4717-fafe-148e657f876f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/components/chatbot.py:285: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6f60a1fa16299ff8be.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6f60a1fa16299ff8be.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0vEFTgUecW98"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
